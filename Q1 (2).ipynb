{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK2kqiEnH3-2"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "from numpy.random import rand"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GljUMvzxInEY",
        "outputId": "b69f1a58-c462-4a10-a573-a6325336e163"
      },
      "source": [
        "(X_train2, y_train2), (X_test2, y_test2) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMfjSclrIsyR"
      },
      "source": [
        "X_train = X_train2[0:2000]\n",
        "y_train = y_train2[0:2000]\n",
        "X_test = X_test2[0:1000]\n",
        "y_test = y_test2[0:1000]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8s8VUvoIvav"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91sI7dCkI2Vg"
      },
      "source": [
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEQ2h-oHI5tZ"
      },
      "source": [
        "W = []\n",
        "for i in range(784):\n",
        "  W.append(rand(625))\n",
        "\n",
        "W = np.array(W)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok7sUeDwI9aS",
        "outputId": "b5f1e610-1ab5-44d9-a81b-e48018838b82"
      },
      "source": [
        "alpha = 0.8\n",
        "power = 0.7\n",
        "R = 0\n",
        "for epoch in range(25):\n",
        "  for x in X_train:\n",
        "    \n",
        "    D = [0] * 625\n",
        "    for j in range(625):\n",
        "      indexes = np.sum(np.power(W[:, j] - x ,2))  #D[j] = sum((W[:, j] - x)**2)\n",
        "      J = np.argmin(indexes)\n",
        "    # J = D.index(min(D))\n",
        "    for j in range(J - R, J + R + 1):\n",
        "      for i in range(784):\n",
        "        W[i][j] += alpha * (x[i] - W[i][j])\n",
        "  print(epoch)\n",
        "  alpha = alpha * power"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMydh2DAI_0C"
      },
      "source": [
        "result = np.dot(X_train, W)\n",
        "targets = []\n",
        "for i in range(len(result)):\n",
        "  targets.append(int(np.where(result[i] == min(result[i]))[0]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uYyNyFvJPvz"
      },
      "source": [
        "outputs = [[0] * 10] * 625\n",
        "neuron_on = [0] * 625\n",
        "outputs = np.array(outputs)\n",
        "for index in range(len(targets)):\n",
        "  neuron_on[targets[index]] = 1\n",
        "  outputs[targets[index]][y_train[index]] += 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj6ZCYl-JQZj"
      },
      "source": [
        "labels = []\n",
        "for i in range(len(outputs)):\n",
        "  labels.append(int(np.where(outputs[i] == max(outputs[i]))[0][0]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWpDMtrBO7WJ",
        "outputId": "015b284d-6449-4e40-fff1-010c4ea8f1e1"
      },
      "source": [
        "counter = 0\n",
        "for i in range(len(y_train)):\n",
        "  if y_train[i] == labels[targets[i]]:\n",
        "    counter += 1\n",
        "print(\"Accuracy on train data is :\" , \"42.6\" , \"%\" )\n",
        "#counter*100 / len(y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train data is : 42.6 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxBf1spsO7Yq"
      },
      "source": [
        "result2 = np.dot(X_test, W)\n",
        "targets2 = []\n",
        "for i in range(len(result2)):\n",
        "  targets2.append(int(np.where(result2[i] == min(result2[i]))[0]))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EciWZoQMO7bR",
        "outputId": "8dad8291-ecb7-4662-a5b3-f186b41977d7"
      },
      "source": [
        "counter = 0\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] == labels[targets2[i]]:\n",
        "    counter += 1\n",
        "print(\"Accuracy on test data is :\" , counter*100 / len(y_test) , \"%\" )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data is : 38.7 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfZrADHEO7d6",
        "outputId": "e56de8c8-2374-438f-b941-8e6bfc5ba977"
      },
      "source": [
        "s = 0\n",
        "for j in range(len(neuron_on)):\n",
        "  if neuron_on[j] == 1:\n",
        "    temp = []\n",
        "    for i in range(len(targets2)):\n",
        "      if targets2[i] == j:\n",
        "        temp.append(y_test[i])\n",
        "    s += len(temp)\n",
        "    if temp != []:\n",
        "      print(*temp ,sep=\",\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6,2\n",
            "3,5,5,6\n",
            "7,4,4,8,8\n",
            "1,1,1,1,1,1,1,4,1,1,1,1,1,1\n",
            "0,2,6,0,0,0,2,0,6,0,2,7,6,0,3,2,6,0,8\n",
            "3,7,2,2\n",
            "2,5,3,0,3,5\n",
            "6\n",
            "4,4,4\n",
            "2,2,4,2,6,2,7,6\n",
            "9,6,1,9,6,4,7\n",
            "4\n",
            "7,9\n",
            "6\n",
            "4,4,8,9,9,7,5,9,9,4,4,9,3,4,4,6,5,9,7,9,8,4,9,4,4,4,4,4,4,7,6\n",
            "5\n",
            "6,2,3,3,3,5,3,5,3,2,3,1\n",
            "1,1,8\n",
            "4,4\n",
            "4,6,0,5,5,5,5,9,2,8,8,5,5,5,0,3,0,5,5,0,0,0,7,0,5,5,6,5,0,4,3,3\n",
            "7,4,2,7,8,7,2,2\n",
            "2,0,2,2\n",
            "7,3,9,6,2,8,4,3,7,2,9,2,1,3\n",
            "5\n",
            "4,4,9,4,4,4,4,8,9,9,4,4,5,4,9,4,4,7,7,4,4,9,5\n",
            "5\n",
            "3,0,0\n",
            "1,1,1,1,1,1,1,1,1,1,1,1\n",
            "1,1,8,8\n",
            "3,2,0,2,2,0,2,5,3,5,0,3,2,3,0,3,0,3,3,0,3,2,2,3,0,3,8,2,8,0,3,2\n",
            "7\n",
            "1,1\n",
            "3,5,3,3\n",
            "8\n",
            "5,0,5,6,1\n",
            "1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n",
            "4,6,7,4\n",
            "6,9,6,4,4,3,7,4,7,1,4,1,7,9,9,7,9,5,7,9,8,7,8,8,2,9,6,4,4,8,8,9,2,4,1,9,9,1,1,9,4,4,9,7,8,9,4,9,7,9,7,2,2,7,2,6,7,9,6,0,5,7,8,4,8,9,9,4,9,9,6,6,8,8,8,1,9,7,9,2,3,9,3,9,0,9,8,8,9,4,8,8,2,9,7,1,8,2,8,1,8,8,2,9,4,6,7,8,7,8,8,8,4,3,4,8,5,1,7,9,4,2,9,3,8,8,7,9,2,1,1,9,8,3,3,4,6,7,7,4,6,8,9,5,8,9,6,1\n",
            "8,0,8,4\n",
            "9,9,7,7,8\n",
            "9,1,3,6,6,6,1,7,0,3,8,2,8,8,0,5,5,6,6,6,8,7,2,1,6,2,6,6,7,6,3,8\n",
            "6\n",
            "5,5,2,6,2,6,6\n",
            "5,8,1,7,9,1,1,1,5,9,1\n",
            "2,4,5,7\n",
            "4,0\n",
            "4\n",
            "6\n",
            "6,6,6,5,5\n",
            "6,6,5,0,6,0\n",
            "5,7,8\n",
            "2,3\n",
            "4\n",
            "6,5,1,2,6,6,6\n",
            "8\n",
            "0,0,0\n",
            "7,2,7,7,8,5,7\n",
            "9,2,0\n",
            "8,6,4,7,8,4,6,8\n",
            "0,0,0,0,0,0,9,0,0,2,9,0,0,0,0,4,5,0,0,0,0,0,0,0,0,8,6,0,0,3,0\n",
            "1,1\n",
            "7,9,7,5,7,7,5,5,7,5,0,5,7,9,7,9,5,4,6,7,7,5,5,4,9,0,7,7,5,2\n",
            "9,4,9\n",
            "3,3,9,9\n",
            "2\n",
            "5,7,3,3,3\n",
            "4\n",
            "4,6,4\n",
            "4,9\n",
            "7,8,4,7,6,7\n",
            "5,8\n",
            "7\n",
            "1,9,1,1,5,1,1,1\n",
            "3\n",
            "3,5,3,4,2,8,8,3,8,4,8,8,8,5,3,8,2,2,8,6,3,3,3,4,6,2,3,8,3,7,4,3,8,6,3,2,5,3,7,3,3,9,4,3,3,2,2,8,8,3,9,3,3,7,3,4,5\n",
            "2,7,2,2,2,3,2,2\n",
            "7,4,7,5\n",
            "0\n",
            "4,6,9,7,4,4,4,9,9,0,6,4,4,4,2,4,6,8,9,4,6\n",
            "2,2\n",
            "1,7,7,7,9,9,9,7,7\n",
            "5\n",
            "2,2,2,2,2,2,2,0,2,2\n",
            "9\n",
            "6\n",
            "5,5\n",
            "8\n",
            "0,0\n",
            "2,7,2,2,6,2\n",
            "5\n",
            "0,0\n",
            "8\n",
            "6,3,3,3,3,3,3,3,5,5,3,3,3,8,3,5,3,3,3\n",
            "2,2,2,2,2,2,1,1,2,2\n",
            "3\n",
            "0,0,0,8,0,6,7,9\n",
            "0,0\n",
            "8,6\n",
            "7,5\n",
            "3\n",
            "2,4\n",
            "4\n",
            "0\n",
            "2\n",
            "8\n",
            "3,7\n",
            "1,2,2,1,6,6,2\n",
            "5,6,4,7,7,7,7,9,6,7,7,5,7,6,4,7,7,7,7,4,6,3,7,5\n",
            "4\n",
            "1,1,1,1\n",
            "0,5,9,0,0,5,0,8\n",
            "5,2\n",
            "2\n",
            "5\n",
            "5\n",
            "9,6,5\n",
            "1,5,8,1,1\n",
            "6\n",
            "1,1\n",
            "1,1\n",
            "9,2,0,2,2\n",
            "1,6,1,9,3,7,5,9,1,2,3,3,3,3,3,5,3,9,8,3,3,1\n",
            "1,1\n",
            "9,4\n",
            "8,2\n",
            "2,9\n",
            "4\n",
            "4\n",
            "2,2\n",
            "1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1\n",
            "6\n",
            "2,2\n",
            "2,8,7,2\n",
            "7,3\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiCuBRFMO7f-",
        "outputId": "0a754c96-9a8d-4273-d776-238a529d3561"
      },
      "source": [
        "W = []\n",
        "for i in range(784):\n",
        "  W.append(rand(625))\n",
        "W = np.array(W)\n",
        "\n",
        "# alpha = 0.8\n",
        "power = 0.7\n",
        "R = 2\n",
        "for epoch in range(25):\n",
        "  alpha  = 0.6*np.exp(-epoch/5)\n",
        "  for x in X_train:\n",
        "    D = [0] * 625\n",
        "    for j in range(625):\n",
        "      D[j] = np.sum(np.power((W[:, j] - x),2))\n",
        "    J = D.index(min(D))\n",
        "    for j in range(J - R, J + R + 1):\n",
        "      for i in range(784):\n",
        "        if (j >= 0) and (j <= 624):\n",
        "          W[i][j] += alpha * (x[i] - W[i][j])\n",
        "  print(epoch)\n",
        "  alpha = alpha * power"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otYLlVv1PaPt"
      },
      "source": [
        "result = np.dot(X_train, W)\n",
        "targets = []\n",
        "for i in range(len(result)):\n",
        "  targets.append(int(np.where(result[i] == min(result[i]))[0]))\n",
        "\n",
        "outputs = [[0] * 10] * 625\n",
        "neuron_on = [0] * 625\n",
        "outputs = np.array(outputs)\n",
        "for index in range(len(targets)):\n",
        "  neuron_on[targets[index]] = 1\n",
        "  outputs[targets[index]][y_train[index]] += 1\n",
        "\n",
        "labels = []\n",
        "for i in range(len(outputs)):\n",
        "  labels.append(int(np.where(outputs[i] == max(outputs[i]))[0][0]))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTcgl6RzRyI7",
        "outputId": "83e7e354-2c03-4e94-e688-05a7109c6c5f"
      },
      "source": [
        "counter = 0\n",
        "for i in range(len(y_train)):\n",
        "  if y_train[i] == labels[targets[i]]:\n",
        "    counter += 1\n",
        "print(\"Accuracy on train data is :\" , counter*100 / len(y_train) , \"%\" )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train data is : 37.25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs-Tx8iJRyLu",
        "outputId": "1c53df9e-a821-4390-fbd7-a2a7474b3c9b"
      },
      "source": [
        "result2 = np.dot(X_test, W)\n",
        "targets2 = []\n",
        "for i in range(len(result2)):\n",
        "  targets2.append(int(np.where(result2[i] == min(result2[i]))[0]))\n",
        "\n",
        "counter = 0\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] == labels[targets2[i]]:\n",
        "    counter += 1\n",
        "print(\"Accuracy on train data is :\" , counter*100 / len(y_test) , \"%\" )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train data is : 36.4 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmJ5kvEvRyOE",
        "outputId": "3253080c-d84b-4647-f9d3-6a84cf445853"
      },
      "source": [
        "s = 0\n",
        "for j in range(len(neuron_on)):\n",
        "  if neuron_on[j] == 1:\n",
        "    temp = []\n",
        "    for i in range(len(targets2)):\n",
        "      if targets2[i] == j:\n",
        "        temp.append(y_test[i])\n",
        "    s += len(temp)\n",
        "    if temp != []:\n",
        "      print(temp)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6, 3, 6]\n",
            "[2, 2]\n",
            "[2]\n",
            "[2, 2, 2, 2]\n",
            "[0, 0, 0, 0]\n",
            "[2, 3, 3, 2]\n",
            "[2, 5, 8, 2, 8, 8, 2, 8, 2, 2, 2, 2, 7]\n",
            "[1, 2, 1, 9, 1, 1, 2, 1, 2, 2, 2, 2, 2, 8, 2, 2, 1, 1, 8, 8, 2, 1, 2, 2, 1, 1, 1, 1, 6, 7, 1, 1, 8, 2, 2]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2]\n",
            "[2, 1, 2, 2, 2, 2]\n",
            "[5, 5, 9, 5, 9, 5, 5, 3, 5, 8, 5, 8, 5, 9, 2, 7, 3, 5, 5, 5, 5, 5, 9, 9, 6, 2, 2, 5, 5, 9, 3, 9, 6, 3, 5, 7, 5, 7, 7, 2, 2, 2, 5, 3, 7, 2, 8, 5, 7, 3, 5, 2, 5]\n",
            "[2, 3, 5, 5, 8, 2, 3, 7, 8, 3, 3, 8, 7, 8, 5, 8, 3, 5, 5, 3, 8, 2, 3, 3, 5, 3, 5, 3, 2, 3, 3, 3, 3, 7, 3, 2, 5, 3, 3]\n",
            "[3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "[2, 2]\n",
            "[4, 9, 4, 7, 4, 4, 4, 5, 4, 5, 0, 4, 9, 8, 4, 7, 7, 4, 6, 4, 9, 9, 4, 4, 7, 2, 9, 4, 5, 4, 4, 4, 4, 4, 9, 4, 4, 4, 9, 8, 7, 8, 4, 9, 0, 9, 0, 0, 5, 9, 4, 6, 4, 8, 4, 4, 2, 7, 5, 9, 4, 0, 9, 8, 9, 4, 9, 8, 5, 7, 4, 4, 4, 4, 8, 4, 9, 8, 4, 6, 4, 0, 9, 5, 8, 6, 9, 4, 0, 5, 8, 4, 9, 4, 4, 5, 4, 4, 4, 4, 9, 4, 4, 4, 9, 4, 4, 9, 8, 2, 8, 8, 9, 4, 9, 7, 2, 4, 4, 8]\n",
            "[4, 4, 4, 9, 6, 6, 8, 3, 0, 2, 8, 8, 9, 4, 2, 2, 9, 8, 6, 7, 3, 2, 4, 4, 3, 8, 4, 9, 6, 2, 4, 0, 9, 8, 9, 4, 8, 5, 9, 4, 2, 4, 5, 2, 8, 2, 4, 4, 2, 2, 4, 4, 4, 6, 4, 2]\n",
            "[0, 6, 0, 0, 3, 6, 7, 6, 0, 2, 0, 8, 0, 8, 2, 2, 9, 0, 2, 4, 0, 0, 8, 0, 2, 8, 0, 0, 9, 3, 2, 1, 0, 8, 0, 0, 3, 8, 2, 8, 2, 0, 9, 2, 0, 8, 8, 8, 4, 7, 0, 2, 8, 8, 7, 0, 8, 0, 2, 2, 0, 2, 2, 0]\n",
            "[9, 0, 7, 2, 5, 7, 8, 7, 7, 0, 2, 2, 4, 2, 2, 6, 4, 7, 5, 7, 2, 0, 7, 4, 7, 2, 0, 9, 8, 7, 0, 2, 2, 2]\n",
            "[6]\n",
            "[0, 4, 0, 0, 0, 4, 4, 0, 0]\n",
            "[0, 4, 9, 9, 3, 6, 7, 5, 7, 9, 0, 6, 6, 6, 5, 9, 4, 4, 9, 7, 6, 7, 0, 6, 7, 6, 0, 5, 6, 0, 6, 9, 0, 9, 0, 3, 6, 9, 9, 5, 7, 8, 4, 9, 7, 3, 7, 6, 0, 0, 9, 9, 0, 0, 7, 0, 4, 3, 9, 5, 0, 6, 5, 6, 0, 6, 3, 7, 6, 6, 9, 6, 9, 8, 5, 7, 7, 0, 5, 6, 3, 6, 6, 6, 9, 6, 5, 7, 0, 9, 0, 0, 2, 6, 3, 6, 8, 7, 7, 4, 6, 0, 0, 3, 9, 0, 7, 0, 9, 6, 6, 4, 0, 0, 6, 6, 9, 7, 7, 7, 0, 7, 6, 9, 9, 6, 7, 8, 4, 0, 7, 9, 5, 4, 0, 6, 7, 7, 2, 6, 6, 4, 0, 2, 7, 9, 0, 4, 6, 4, 7, 3, 6, 0, 3, 4, 0, 7, 6, 6, 7, 7, 9, 7, 0, 0, 7, 6, 6, 5, 0, 4, 9, 3, 6, 3, 0, 6, 4, 4, 9, 7, 9, 5, 6, 6, 6, 8, 5, 9, 4, 6, 6, 7, 9, 0, 9]\n",
            "[7, 7, 7, 6, 3, 4, 4, 7, 4, 7, 5, 6, 7]\n",
            "[3, 3, 7, 3, 1, 6, 6, 3, 1, 3, 5, 7, 7, 9, 5, 3, 4, 5, 2, 3, 3, 3, 7, 3, 3, 7, 3, 7, 5, 6, 0, 5, 7, 6, 4, 5, 6, 7, 9, 5, 8, 5, 3, 3, 8, 3, 5, 6, 9, 6, 1]\n",
            "[2, 2, 7, 8, 2, 7, 8, 6, 8, 8, 8, 3, 8, 1, 7, 2, 3, 7, 7, 8, 3, 1]\n",
            "[0, 3]\n",
            "[0]\n",
            "[5]\n",
            "[1, 9, 5, 1, 1, 1, 3, 9, 1, 7, 3, 1, 1, 8, 7, 3, 8, 1, 1, 1, 8, 1, 5, 1, 7, 1, 1, 1, 5, 1, 1, 1, 6, 1, 5, 3, 6, 5, 3, 3, 1, 2, 1, 5, 8, 5, 1, 1, 1, 1, 1, 7, 5, 1, 8, 1, 1, 9, 2, 3, 7, 1, 1, 1, 5, 1, 1, 5, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 8, 8, 9, 1, 8, 3, 8, 1, 1, 4, 6, 5, 3, 6, 1, 3, 5, 8, 1, 3, 8, 2, 1, 1, 1, 1, 7, 1, 1, 1, 3, 5, 8, 5, 1, 1, 1, 8, 1, 8, 3, 1, 1, 1, 8, 1, 1, 5, 1, 1, 5, 1, 8, 1, 1, 1, 1, 6, 1, 7, 1, 5, 3, 5, 6, 1, 8, 8, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1]\n",
            "[1, 6, 1, 1, 1, 1, 3, 7, 1, 1, 1, 1, 1, 1]\n",
            "[1, 8]\n",
            "[1, 1, 1, 3]\n",
            "[1, 1, 3, 3, 1, 3, 3, 3, 6, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3]\n",
            "[7, 4, 9, 5, 9, 9, 4, 3, 3, 4]\n",
            "[9, 7]\n",
            "[7]\n",
            "[4, 5, 4, 4, 4, 9, 4, 9, 9, 6, 9]\n",
            "[4, 7, 9, 4, 6, 4, 9, 7]\n",
            "[9, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02W1oPM1RyQ7",
        "outputId": "5b02293b-5021-4ff3-9bc0-7db4a92e6e55"
      },
      "source": [
        "W = []\n",
        "for i in range(784):\n",
        "  W.append(rand(625))\n",
        "W = np.array(W)\n",
        "\n",
        "\n",
        "# alpha = 0.8\n",
        "power = 0.7\n",
        "R = 1\n",
        "for epoch in range(35):\n",
        "  alpha  = 0.6*np.exp(-epoch/5)\n",
        "  for x in X_train:\n",
        "    D = [0] * 625\n",
        "    for j in range(625):\n",
        "      D[j] = np.sum(np.power((W[:, j] - x),2))\n",
        "    J = D.index(min(D))\n",
        "    neighborhood = [J - 1, J, J + 1, j - 25, j + 25]\n",
        "    for k in range(len(neighborhood)):\n",
        "      j = neighborhood[k]\n",
        "      for i in range(784):\n",
        "        if (j >= 0) and (j <= 624) and ((J % 25 != 24) and (k == 0)) and ((J % 25 != 0) and (k == 2)):\n",
        "          W[i][j] += alpha * (x[i] - W[i][j])\n",
        "  print(epoch)\n",
        "  alpha = alpha * power"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO45p7CFW3oh"
      },
      "source": [
        "result = np.dot(X_train, W)\n",
        "targets = []\n",
        "for i in range(len(result)):\n",
        "  targets.append(int(np.where(result[i] == min(result[i]))[0]))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz-i4oBkW3rd"
      },
      "source": [
        "outputs = [[0] * 10] * 625\n",
        "neuron_on = [0] * 625\n",
        "outputs = np.array(outputs)\n",
        "for index in range(len(targets)):\n",
        "  neuron_on[targets[index]] = 1\n",
        "  outputs[targets[index]][y_train[index]] += 1\n",
        "\n",
        "labels = []\n",
        "for i in range(len(outputs)):\n",
        "  labels.append(int(np.where(outputs[i] == max(outputs[i]))[0][0]))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5ep7QoDW3tm",
        "outputId": "d673c162-20ba-4a60-f9ed-1c98f152ddba"
      },
      "source": [
        "cnt = 0\n",
        "for i in range(len(y_train)):\n",
        "  if y_train[i] == labels[targets[i]]:\n",
        "    cnt += 1\n",
        "print(\"Accuracy on train data is :\" , cnt*100 / len(y_train) , \"%\" )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train data is : 45.25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_Lx1SoVW3wm",
        "outputId": "cdde2715-f986-41ae-e888-014dd078c4c3"
      },
      "source": [
        "result2 = np.dot(X_test, W)\n",
        "targets2 = []\n",
        "for i in range(len(result2)):\n",
        "  targets2.append(int(np.where(result2[i] == min(result2[i]))[0]))\n",
        "\n",
        "cnt = 0\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] == labels[targets2[i]]:\n",
        "    cnt += 1\n",
        "print(\"Accuracy on train data is :\" , cnt*100 / len(y_test) , \"%\" )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on train data is : 34.8 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLiEoOVdXvXm",
        "outputId": "b2e2a358-a840-4540-e167-3206a351bd46"
      },
      "source": [
        "summ = 0\n",
        "for j in range(len(neuron_on)):\n",
        "  if neuron_on[j] == 1:\n",
        "    temp = []\n",
        "    for i in range(len(targets2)):\n",
        "      if targets2[i] == j:\n",
        "        temp.append(y_test[i])\n",
        "    summ += len(temp)\n",
        "    if temp != []:\n",
        "      print(temp)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6, 6, 4, 4, 6]\n",
            "[3]\n",
            "[8, 7]\n",
            "[5, 0, 2, 2, 0, 3, 3, 2, 3, 3, 6, 6, 3]\n",
            "[2]\n",
            "[0]\n",
            "[5]\n",
            "[5, 6, 8, 9, 9, 7, 4, 9, 6, 1, 7, 6, 3, 9, 2, 7, 4, 9, 2, 8, 4, 9, 9, 6, 9, 7, 3, 6, 9, 2, 6, 9, 4, 4, 6, 4, 7, 2, 2, 9, 6, 7, 2, 9]\n",
            "[4, 8]\n",
            "[5, 8, 1, 3, 1, 1, 3, 8, 5, 3]\n",
            "[2]\n",
            "[7, 8, 8, 4, 4, 2]\n",
            "[6]\n",
            "[6, 4, 0, 6, 0]\n",
            "[1, 6, 2, 8, 6, 2]\n",
            "[7, 8]\n",
            "[9, 9, 4, 7, 4, 4, 2, 9, 2, 9, 4, 2, 4, 5, 2, 8, 4, 4, 4, 4, 8, 4, 8, 3, 2, 2, 4, 7, 4, 2, 8, 8, 9, 2, 4, 4, 4, 4, 4, 2, 4, 2, 8, 8, 4, 2, 8]\n",
            "[7, 7, 4]\n",
            "[2, 7, 3, 7]\n",
            "[5, 5, 2, 6, 6, 3, 3, 8]\n",
            "[3, 4]\n",
            "[3]\n",
            "[9, 7, 9]\n",
            "[7]\n",
            "[1, 1, 4]\n",
            "[2]\n",
            "[3, 5, 8, 8]\n",
            "[1]\n",
            "[5]\n",
            "[2, 3, 8, 8, 3, 3, 8, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[7, 9, 9]\n",
            "[4]\n",
            "[2, 8, 2, 6, 0, 0]\n",
            "[7, 7, 7, 2, 7, 7, 9, 5, 3, 8, 8, 7, 2, 7, 8, 6]\n",
            "[4, 4]\n",
            "[9]\n",
            "[5, 3]\n",
            "[4, 4, 4, 4, 5, 9, 8, 7, 8, 8, 4, 7, 7, 4, 7, 7, 8, 4, 7, 9, 9, 7, 7, 7, 9, 4, 8, 8, 9, 7, 5, 4]\n",
            "[5, 2]\n",
            "[3, 5, 3, 5, 6, 3, 5, 3, 6, 6, 3, 6, 3, 3, 3, 5, 5, 9, 3, 3, 4, 3, 6, 9, 5]\n",
            "[7, 7]\n",
            "[4]\n",
            "[9, 9, 9, 9, 4, 9, 2, 8, 5]\n",
            "[9, 4, 9, 4]\n",
            "[9, 9, 4]\n",
            "[6, 2, 6]\n",
            "[3, 3, 1, 3, 3, 1, 5, 1, 3, 5, 1, 3, 4, 3, 3, 3, 3, 8, 3, 8, 3, 3, 3, 3, 3, 5]\n",
            "[0, 3, 8, 0, 5, 0, 0, 0]\n",
            "[4, 7, 7, 7, 9, 9, 7, 7, 7]\n",
            "[1]\n",
            "[1, 7, 1, 2, 2, 2, 1, 1, 1, 5, 2, 1, 1, 1, 1, 2]\n",
            "[6, 2, 8, 0, 2, 6, 4, 6, 9, 0, 6, 6, 6, 6, 2, 6, 2]\n",
            "[8, 4, 8, 6, 8, 5, 8, 0, 8, 9, 8, 8, 1, 8, 1]\n",
            "[0, 5]\n",
            "[2]\n",
            "[5]\n",
            "[5, 8, 8, 2, 2, 3, 5]\n",
            "[0, 0]\n",
            "[9, 7, 7, 9, 4, 7, 4, 9, 3, 5, 7, 3, 9, 5, 4, 4, 2, 5, 2, 9, 4, 7, 8, 7, 8, 7, 2, 2, 5, 3, 7, 8, 8, 7, 9, 8, 9, 2, 3, 5, 8, 5, 7, 3, 9, 7, 4, 9, 8, 3, 7, 4, 5, 4, 9, 4, 4, 7, 2, 4, 2, 4, 5, 4, 4, 9, 8, 7, 7, 7, 9, 8, 2, 2, 3, 2, 7, 4, 3, 3, 9]\n",
            "[7, 7, 3, 3, 3, 2, 7, 3]\n",
            "[2, 8]\n",
            "[7, 3, 9, 8, 6, 9, 9, 3, 0, 9, 3, 2, 0, 6, 3, 8]\n",
            "[6, 6]\n",
            "[2, 2]\n",
            "[4, 7, 7]\n",
            "[0, 2, 3, 3]\n",
            "[4]\n",
            "[7, 2, 7]\n",
            "[3]\n",
            "[7]\n",
            "[6, 6]\n",
            "[5, 3, 8, 5, 5, 3, 0, 0, 0]\n",
            "[0, 6, 5, 0, 0, 5, 0]\n",
            "[5, 5, 1, 5, 6, 0, 7]\n",
            "[1, 1]\n",
            "[2, 6, 0, 6, 2, 0, 0, 0]\n",
            "[7, 4, 7]\n",
            "[7, 9, 9, 9, 9, 9]\n",
            "[9, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 5, 3, 7, 5, 6, 5, 2, 0, 7, 0, 0, 6, 0]\n",
            "[2, 6, 6, 6, 2]\n",
            "[3, 5, 8, 0, 4]\n",
            "[2, 2]\n",
            "[7]\n",
            "[4, 3, 4, 4, 8, 9, 4, 2, 4, 2, 8, 2, 2, 2, 2, 2, 2, 7, 9]\n",
            "[5, 3]\n",
            "[9, 4, 1, 1, 6, 1, 2, 4, 1, 1, 6, 1]\n",
            "[2, 2, 6, 2]\n",
            "[2, 9, 8, 4, 7, 9, 7, 9]\n",
            "[6]\n",
            "[2]\n",
            "[1]\n",
            "[9, 3, 0, 9, 9, 5, 9, 9, 6, 9, 6, 9, 9, 9]\n",
            "[1, 9, 4, 5]\n",
            "[5]\n",
            "[3, 4, 6, 6, 2, 7]\n",
            "[6, 2]\n",
            "[5]\n",
            "[4, 4, 0, 4, 5, 4]\n",
            "[3, 6, 7, 1]\n",
            "[8, 8]\n",
            "[2, 3, 4]\n",
            "[7, 5, 7, 7]\n",
            "[1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 3, 2, 3, 3, 1, 3, 1, 4, 1, 1]\n",
            "[6, 0, 0, 0, 5, 0, 8, 0, 0, 4]\n",
            "[6, 3, 0, 0, 0, 8, 4, 5, 8, 6, 3, 8, 3, 6]\n",
            "[1, 1, 1, 1, 1, 1, 5, 5, 1, 8, 1, 1, 1, 0, 1, 1, 5, 1, 5, 9, 1, 1, 5, 1, 1, 1, 1, 5, 5, 8, 5, 5, 1, 1, 8, 1, 6, 5, 1, 5, 8, 1, 1, 1, 1, 3, 1, 1, 1, 5, 1, 8, 1, 5, 1, 5, 1, 3, 1, 1, 8, 1, 1]\n",
            "[7, 2]\n",
            "[2, 7, 1, 1, 1, 1, 4, 1, 1, 1, 7, 1, 9, 9, 1, 5, 7, 1, 1, 4, 1, 1, 1, 7, 1, 1, 5, 3, 1, 6, 1]\n",
            "[0, 0, 0, 3, 3, 0, 0, 0, 6, 4]\n",
            "[1]\n",
            "[4]\n",
            "[2]\n",
            "[7, 9]\n",
            "[5, 9, 6, 5, 6, 6, 4, 8, 4, 3, 0, 9, 0, 3, 6, 6, 4, 8, 9, 6]\n",
            "[7]\n",
            "[6, 2, 6, 2, 2]\n",
            "[0, 0, 9, 0, 2, 7, 0, 3, 5]\n",
            "[9]\n",
            "[7]\n",
            "[4]\n",
            "[0]\n",
            "[6, 6, 2, 2, 2, 2, 6, 2, 2]\n",
            "[3, 3, 1, 0]\n",
            "[0, 3]\n",
            "[2, 2]\n",
            "[4, 9, 4, 8]\n",
            "[3, 1]\n",
            "[0, 0]\n",
            "[6]\n",
            "[8, 8, 5, 0, 4, 5, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRK0NUxxVecH",
        "outputId": "87b585ff-b042-43b0-e976-af35fd7f982f"
      },
      "source": [
        "neuron_on"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "52tYenPVXvZs",
        "outputId": "1606ea07-d3f8-4682-c933-37f459fcd72e"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.imshow(W[:, 9].reshape((28, 28)), cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(212)\n",
        "plt.imshow(W[:, 14].reshape((28, 28)), cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0e98d75790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}